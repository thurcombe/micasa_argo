# All values are passed to the dependency chart "zfs-exporter".
# This config runs the exporter as a DaemonSet on your k3s node, exposes :9134,
# and mounts the host's ZFS bits so metrics include pool health.

zfs-exporter:
  fullnameOverride: zfs-exporter
  kind: DaemonSet

  image:
    repository: enix/zfs-exporter
    tag: "2.3.10"           # exporter app version
    pullPolicy: IfNotPresent

  # Exporter flags (keep it lean; enable snapshots if desired)
  args:
    - --deadline=8s
    - --web.listen-address=:9134
    - --collector.pool
    - --collector.dataset-filesystem
    - --collector.dataset-volume
    # - --collector.dataset-snapshot

  service:
    enabled: true
    type: ClusterIP
    port: 9134

  # Needs host ZFS access
  securityContext:
    privileged: true
    runAsUser: 0

  extraVolumes:
    - name: dev
      hostPath: { path: /dev }
    - name: etc-zfs
      hostPath: { path: /etc/zfs, type: DirectoryOrCreate }
    - name: usr-sbin
      hostPath: { path: /usr/sbin }
    - name: sbin
      hostPath: { path: /sbin }

  extraVolumeMounts:
    - { name: dev,      mountPath: /dev }
    - { name: etc-zfs,  mountPath: /etc/zfs,  readOnly: true }
    - { name: usr-sbin, mountPath: /usr/sbin, readOnly: true }
    - { name: sbin,     mountPath: /sbin,     readOnly: true }

  nodeSelector:
    kubernetes.io/os: linux
  tolerations:
    - operator: Exists

  resources: {}  # tune if you want
