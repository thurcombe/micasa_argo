# --- kube-state-metrics (metrics source for pod state) ---
kube-state-metrics:
  # Stable name so the Service is just "kube-state-metrics" on port 8080
  fullnameOverride: kube-state-metrics

# --- VictoriaMetrics Single (tiny TSDB; only scraped KSM) ---
victoria-metrics-single:
  # Ensures the Service name becomes: victoria-alerts-vmsingle-server (with your release name)
  nameOverride: vmsingle

  server:
    # keep persistence as you set it
    persistentVolume:
      enabled: true
      storageClassName: local-path
      size: 1Gi

    retentionPeriod: 7d

    resources:
      requests:
        cpu: 50m
        memory: 256Mi
      limits:
        cpu: 200m
        memory: 512Mi

    service:
      type: ClusterIP

    scrape:
      enabled: true
      # IMPORTANT: must be a YAML OBJECT (not a block string)
      config:
        global:
          scrape_interval: 30s
          scrape_timeout: 10s
        scrape_configs:
          - job_name: "kube-state-metrics"
            static_configs:
              - targets: ["kube-state-metrics:8080"]

# --- VMAlert (evaluates rules, alerts to your existing Alertmanager) ---
victoria-metrics-alert:
  server:
    # keep your naming
    fullnameOverride: vmalert

    # vmalert reads from VM Singleâ€™s Prom-compatible API
    datasource:
      url: "http://victoria-alerts-vmsingle-server:8428"

    # (Optional) persist recording rules / alert state; not required for alerting-only
    remote:
      write:
        url: "http://victoria-alerts-vmsingle-server:8428/api/v1/write"
      read:
        url: "http://victoria-alerts-vmsingle-server:8428"

    # Send to your existing Alertmanager Service
    notifier:
      alertmanager:
        url: "http://alertmanager.alertmanager.svc:9093"

    # vmalert flag -> evaluate every 30s
    extraArgs:
      evaluationInterval: 30s

    # Inline alert rules using ONLY kube-state-metrics metrics
    # Only alert for pods that are Running (or Pending where it makes sense),
    # so Completed (Succeeded) pods are ignored.
    config:
      alerts:
        groups:
          - name: k8s.pods.core
            rules:
              # CrashLoopBackOff only if pod is Running or Pending
              - alert: KubePodCrashLoopBackOff
                expr: |
                  (sum by (namespace, pod) (kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff"}) > 0)
                  and on (namespace, pod) kube_pod_status_phase{phase=~"Running|Pending"}
                for: 5m
                labels: { severity: critical }
                annotations:
                  summary: "CrashLoopBackOff"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} in CrashLoopBackOff >5m."

              # ImagePullBackOff only if pod is Running or Pending
              - alert: KubePodImagePullBackOff
                expr: |
                  (sum by (namespace, pod) (kube_pod_container_status_waiting_reason{reason="ImagePullBackOff"}) > 0)
                  and on (namespace, pod) kube_pod_status_phase{phase=~"Running|Pending"}
                for: 5m
                labels: { severity: warning }
                annotations:
                  summary: "ImagePullBackOff"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} failing to pull image."

              # Pending too long (already scoped to Pending phase)
              - alert: KubePodPendingTooLong
                expr: |
                  max by (namespace, pod) (kube_pod_status_phase{phase="Pending"}) > 0
                for: 10m
                labels: { severity: warning }
                annotations:
                  summary: "Pod pending >10m"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} pending >10m."

              # Not Ready only if pod is Running
              - alert: KubePodNotReady
                expr: |
                  ((max by (namespace, pod) (kube_pod_status_ready{condition="true"} == 0)) > 0)
                  and on (namespace, pod) kube_pod_status_phase{phase="Running"}
                for: 5m
                labels: { severity: warning }
                annotations:
                  summary: "Pod not Ready >5m"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} not Ready >5m."

              # OOMKilled only if pod is Running or Pending (ignore finished pods)
              - alert: KubePodOOMKilled
                expr: |
                  (sum by (namespace, pod) (kube_pod_container_status_terminated_reason{reason="OOMKilled"}) > 0)
                  and on (namespace, pod) kube_pod_status_phase{phase=~"Running|Pending"}
                for: 1m
                labels: { severity: critical }
                annotations:
                  summary: "OOMKilled"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} had container(s) OOMKilled."
