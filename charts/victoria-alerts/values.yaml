# --- kube-state-metrics (metrics source for pod state) ---
kube-state-metrics:
  fullnameOverride: kube-state-metrics

# --- VictoriaMetrics Single (tiny TSDB; only scraped KSM) ---
victoria-metrics-single:
  nameOverride: vmsingle

  server:
    persistentVolume:
      enabled: true
      storageClassName: local-path
      size: 1Gi

    retentionPeriod: 7d

    resources:
      requests:
        cpu: 50m
        memory: 256Mi
      limits:
        cpu: 200m
        memory: 512Mi

    service:
      type: ClusterIP

    scrape:
      enabled: true
      config:
        global:
          scrape_interval: 30s
          scrape_timeout: 10s
        scrape_configs:
          - job_name: "kube-state-metrics"
            static_configs:
              - targets: ["kube-state-metrics:8080"]

# --- VMAlert (evaluates rules, alerts to your existing Alertmanager) ---
victoria-metrics-alert:
  server:
    fullnameOverride: vmalert

    # Read metrics from VM Single
    datasource:
      url: "http://victoria-alerts-vmsingle-server:8428"

    # NOTE: remote read/write removed to avoid the duplicated /api/v1/write path issue.
    # VMAlert does NOT need remote write for alerting-only use.

    # Send to your existing Alertmanager
    notifier:
      alertmanager:
        url: "http://alertmanager.alertmanager.svc:9093"

    extraArgs:
      evaluationInterval: 30s

    # Rules use only KSM metrics; Completed pods are excluded by requiring Running/Pending==1
    config:
      alerts:
        groups:
          - name: k8s.pods.core
            rules:
              # CrashLoopBackOff only if pod is Running or Pending (truthy)
              - alert: KubePodCrashLoopBackOff
                expr: |
                  (sum by (namespace, pod) (kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff"}) > 0)
                  and on (namespace, pod)
                  (max by (namespace, pod) (kube_pod_status_phase{phase=~"Running|Pending"}) == 1)
                for: 5m
                labels: { severity: critical }
                annotations:
                  summary: "CrashLoopBackOff"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} in CrashLoopBackOff >5m."

              # ImagePullBackOff only if pod is Running or Pending
              - alert: KubePodImagePullBackOff
                expr: |
                  (sum by (namespace, pod) (kube_pod_container_status_waiting_reason{reason="ImagePullBackOff"}) > 0)
                  and on (namespace, pod)
                  (max by (namespace, pod) (kube_pod_status_phase{phase=~"Running|Pending"}) == 1)
                for: 5m
                labels: { severity: warning }
                annotations:
                  summary: "ImagePullBackOff"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} failing to pull image."

              # Pending too long (naturally excludes Succeeded)
              - alert: KubePodPendingTooLong
                expr: max by (namespace, pod) (kube_pod_status_phase{phase="Pending"}) > 0
                for: 10m
                labels: { severity: warning }
                annotations:
                  summary: "Pod pending >10m"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} pending >10m."

              # Not Ready only if pod is Running
              - alert: KubePodNotReady
                expr: |
                  (max by (namespace, pod) (kube_pod_status_ready{condition="true"} == 0) > 0)
                  and on (namespace, pod)
                  (max by (namespace, pod) (kube_pod_status_phase{phase="Running"}) == 1)
                for: 5m
                labels: { severity: warning }
                annotations:
                  summary: "Pod not Ready >5m"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} not Ready >5m."

              # OOMKilled only if pod is Running or Pending
              - alert: KubePodOOMKilled
                expr: |
                  (sum by (namespace, pod) (kube_pod_container_status_terminated_reason{reason="OOMKilled"}) > 0)
                  and on (namespace, pod)
                  (max by (namespace, pod) (kube_pod_status_phase{phase=~"Running|Pending"}) == 1)
                for: 1m
                labels: { severity: critical }
                annotations:
                  summary: "OOMKilled"
                  description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} had container(s) OOMKilled."
